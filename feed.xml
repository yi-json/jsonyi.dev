<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://jsonyi.dev/feed.xml" rel="self" type="application/atom+xml"/><link href="https://jsonyi.dev/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-11-30T20:09:04+00:00</updated><id>https://jsonyi.dev/feed.xml</id><title type="html">blank</title><subtitle>A portfolio for Jason Yi. </subtitle><entry><title type="html">Building Synapse: A Borg-like Cluster Scheduler for AI</title><link href="https://jsonyi.dev/blog/2025/synapse/" rel="alternate" type="text/html" title="Building Synapse: A Borg-like Cluster Scheduler for AI"/><published>2025-11-30T00:00:00+00:00</published><updated>2025-11-30T00:00:00+00:00</updated><id>https://jsonyi.dev/blog/2025/synapse</id><content type="html" xml:base="https://jsonyi.dev/blog/2025/synapse/"><![CDATA[<p>Standard web servers are happy to start one by one. If you ask for 50 servers and get 40, your website still works.</p> <p><strong>AI is different.</strong> If you are training a massive model (like Llama 3) across 64 GPUs, and you can only get 63, the job <strong>cannot start</strong>. Standard schedulers will reserve those 63 GPUs and let them sit idle while waiting for the last one. This wastes millions of dollars in compute time.</p> <p>To solve this, I built <strong>Synapse</strong>, a distributed cluster orchestrator that implements <strong>Gang Scheduling</strong> (All-or-Nothing allocation) to maximize resource utilization for AI workloads.</p> <h2 id="architecture-mimicking-borg">Architecture: Mimicking Borg</h2> <p>Synapse follows the classic Google <strong>Borg</strong> architecture (the predecessor to Kubernetes), consisting of three distinct components:</p> <ol> <li><strong>The Brain (Scheduler):</strong> Holds the “state of the world.” It knows which nodes are free, which are busy, and where they are physically located.</li> <li><strong>The Muscle (Worker):</strong> A lightweight agent on every machine. It listens for orders (“Start Job 50”) and executes them using my custom <a href="/blog/2025/carapace/">Carapace runtime</a>.</li> <li><strong>The Interface (CLI):</strong> A <code class="language-plaintext highlighter-rouge">kubectl</code>-like tool for submitting jobs.</li> </ol> <h3 id="topology-awareness">Topology Awareness</h3> <p>In a massive data center, the speed of light matters. If <code class="language-plaintext highlighter-rouge">Node A</code> and <code class="language-plaintext highlighter-rouge">Node B</code> are on the same rack, they can talk instantly. If they are on opposite sides of the building, <strong>latency destroys performance</strong>.</p> <p>Synapse isn’t just looking for <em>any</em> free GPUs. It tries to find GPUs on the <strong>same rack</strong> (or simulated grouping) to maximize training speed.</p> <h2 id="the-core-problem-gang-scheduling">The Core Problem: Gang Scheduling</h2> <p>The biggest challenge in AI infrastructure is ensuring that a job gets <em>all</em> its requested resources at the exact same time.</p> <p>I implemented a <strong>Gang Scheduler</strong> loop that runs every second. It iterates through the pending job queue and performs an atomic check:</p> <div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">// Gang Scheduling: either the job gets ALL its resources, or it waits</span>
<span class="k">func</span> <span class="p">(</span><span class="n">c</span> <span class="o">*</span><span class="n">InMemoryCluster</span><span class="p">)</span> <span class="n">Schedule</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">c</span><span class="o">.</span><span class="n">mu</span><span class="o">.</span><span class="n">Lock</span><span class="p">()</span>
    <span class="k">defer</span> <span class="n">c</span><span class="o">.</span><span class="n">mu</span><span class="o">.</span><span class="n">Unlock</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">job</span> <span class="o">:=</span> <span class="k">range</span> <span class="n">c</span><span class="o">.</span><span class="n">jobQueue</span> <span class="p">{</span>
        <span class="k">if</span> <span class="n">job</span><span class="o">.</span><span class="n">Status</span> <span class="o">!=</span> <span class="n">JobPending</span> <span class="p">{</span> <span class="k">continue</span> <span class="p">}</span>

        <span class="c">// 1. Scan: Can we satisfy this job's requirements?</span>
        <span class="n">neededCPU</span> <span class="o">:=</span> <span class="n">job</span><span class="o">.</span><span class="n">MinCPU</span>
        <span class="n">candidateNodes</span> <span class="o">:=</span> <span class="p">[]</span><span class="o">*</span><span class="n">Node</span><span class="p">{}</span>

        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">node</span> <span class="o">:=</span> <span class="k">range</span> <span class="n">c</span><span class="o">.</span><span class="n">nodes</span> <span class="p">{</span>
            <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">AvailableCPU</span><span class="p">()</span> <span class="o">&gt;</span> <span class="m">0</span> <span class="p">{</span>
                <span class="n">candidateNodes</span> <span class="o">=</span> <span class="nb">append</span><span class="p">(</span><span class="n">candidateNodes</span><span class="p">,</span> <span class="n">node</span><span class="p">)</span>
                <span class="n">neededCPU</span> <span class="o">-=</span> <span class="n">node</span><span class="o">.</span><span class="n">AvailableCPU</span><span class="p">()</span>
            <span class="p">}</span>
        <span class="p">}</span>

        <span class="c">// 2. Decision: If we can't find enough, WAIT.</span>
        <span class="c">// Do not partially allocate resources.</span>
        <span class="k">if</span> <span class="n">neededCPU</span> <span class="o">&gt;</span> <span class="m">0</span> <span class="p">{</span>
            <span class="k">continue</span>
        <span class="p">}</span>

        <span class="c">// 3. Commit: We have enough. Atomically claim resources.</span>
        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">node</span> <span class="o">:=</span> <span class="k">range</span> <span class="n">candidateNodes</span> <span class="p">{</span>
            <span class="c">// ... update node state ...</span>
        <span class="p">}</span>
        <span class="n">job</span><span class="o">.</span><span class="n">Status</span> <span class="o">=</span> <span class="n">JobScheduled</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p>This prevents deadlocks where multiple jobs are holding onto partial resources, waiting for each other to finish.</p> <h2 id="engineering-challenges">Engineering Challenges</h2> <h3 id="1-the-split-brain--bi-directional-grpc">1. The “Split Brain” &amp; Bi-Directional gRPC</h3> <p>In a typical web app, the client talks to the server. But in a cluster, who is the client?</p> <ul> <li><strong>Worker -&gt; Master:</strong> The worker needs to send Heartbeats (“I’m alive”).</li> <li><strong>Master -&gt; Worker:</strong> The master needs to send Commands (“Start Job”).</li> </ul> <p>I solved this by making the Worker act as <strong>both a Client and a Server</strong>.</p> <ul> <li>It runs a background goroutine to push Heartbeats to the Master.</li> <li>It blocks the main thread on a <code class="language-plaintext highlighter-rouge">grpcServer.Serve(lis)</code> call to listen for incoming <code class="language-plaintext highlighter-rouge">StartJob</code> commands.</li> </ul> <h3 id="2-fault-tolerance-the-reaper">2. Fault Tolerance: The Reaper</h3> <p>Distributed systems must assume failure. I implemented a <strong>Reaper</strong> process in the Scheduler that scans for “silent” nodes.</p> <p>If a node hasn’t sent a heartbeat in 10 seconds, the Reaper marks it as <code class="language-plaintext highlighter-rouge">DEAD</code>. This is critical for the Gang Scheduler—if a node dies, we need to know immediately so we don’t try to schedule new jobs on it.</p> <div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">// The Reaper Loop</span>
<span class="k">go</span> <span class="k">func</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">ticker</span> <span class="o">:=</span> <span class="n">time</span><span class="o">.</span><span class="n">NewTicker</span><span class="p">(</span><span class="m">5</span> <span class="o">*</span> <span class="n">time</span><span class="o">.</span><span class="n">Second</span><span class="p">)</span>
    <span class="k">for</span> <span class="k">range</span> <span class="n">ticker</span><span class="o">.</span><span class="n">C</span> <span class="p">{</span>
        <span class="c">// Mark nodes as DEAD if they missed heartbeats</span>
        <span class="n">deadIDs</span> <span class="o">:=</span> <span class="n">clusterManager</span><span class="o">.</span><span class="n">MarkDeadNodes</span><span class="p">(</span><span class="m">10</span> <span class="o">*</span> <span class="n">time</span><span class="o">.</span><span class="n">Second</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">id</span> <span class="o">:=</span> <span class="k">range</span> <span class="n">deadIDs</span> <span class="p">{</span>
            <span class="n">log</span><span class="o">.</span><span class="n">Printf</span><span class="p">(</span><span class="s">"REAPER: Node %s is DEAD"</span><span class="p">,</span> <span class="n">id</span><span class="p">)</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}()</span>
</code></pre></div></div> <h3 id="3-bridging-go-and-rust">3. Bridging Go and Rust</h3> <p>Synapse is written in <strong>Go</strong> (for its excellent concurrency primitives), but the container runtime (Carapace) is written in <strong>Rust</strong> (for low-level Linux control).</p> <p>To bridge them, I used Go’s <code class="language-plaintext highlighter-rouge">os/exec</code> package to perform a <strong>Fork/Exec</strong> operation. The Go worker acts as the supervisor, forking a new process to run the Rust binary, which then sets up the Namespaces and Cgroups for the container.</p> <div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">// Go Worker Code</span>
<span class="n">cmd</span> <span class="o">:=</span> <span class="n">exec</span><span class="o">.</span><span class="n">Command</span><span class="p">(</span><span class="s">"./carapace"</span><span class="p">,</span> <span class="s">"run"</span><span class="p">,</span> <span class="n">req</span><span class="o">.</span><span class="n">JobId</span><span class="p">,</span> <span class="n">req</span><span class="o">.</span><span class="n">Image</span><span class="p">)</span>
<span class="n">cmd</span><span class="o">.</span><span class="n">Stdout</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">Stdout</span>
<span class="n">cmd</span><span class="o">.</span><span class="n">Stderr</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">Stderr</span>
<span class="n">err</span> <span class="o">:=</span> <span class="n">cmd</span><span class="o">.</span><span class="n">Run</span><span class="p">()</span> <span class="c">// Blocks until the container finishes</span>
</code></pre></div></div> <h3 id="4-the-rootfs-problem">4. The RootFS Problem</h3> <p>Since Carapace is a custom runtime, it doesn’t pull images from Docker Hub automatically. If you pass <code class="language-plaintext highlighter-rouge">ubuntu:latest</code>, it fails because it looks for a folder on disk.</p> <p>To make this work, I had to manually export a valid <strong>Root Filesystem (RootFS)</strong> from Docker:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Create a dummy container</span>
docker create <span class="nt">--name</span> temp-export ubuntu:latest
<span class="c"># Export the filesystem to a folder</span>
docker <span class="nb">export </span>temp-export | <span class="nb">tar</span> <span class="nt">-x</span> <span class="nt">-C</span> my-rootfs
</code></pre></div></div> <p>This gave Synapse a real environment to chroot into, allowing it to run actual Linux commands.</p> <h2 id="conclusion">Conclusion</h2> <p>Building Synapse gave me a deep appreciation for the complexity of schedulers like Kubernetes and Borg. It’s not just about finding a free server; it’s about managing state, handling partial failures, and ensuring that expensive hardware isn’t sitting idle.</p> <p>Check out the full source code on <a href="https://github.com/yi-json/synapse">GitHub</a>.</p>]]></content><author><name></name></author><category term="systems"/><category term="distributed-systems"/><category term="go"/><category term="kubernetes"/><category term="borg"/><category term="ai-infra"/><summary type="html"><![CDATA[Solving the "Gang Scheduling" problem for massive AI training jobs using Go and gRPC.]]></summary></entry><entry><title type="html">Building Carapace: A Container Runtime from Scratch in Rust</title><link href="https://jsonyi.dev/blog/2025/carapace/" rel="alternate" type="text/html" title="Building Carapace: A Container Runtime from Scratch in Rust"/><published>2025-11-23T00:00:00+00:00</published><updated>2025-11-23T00:00:00+00:00</updated><id>https://jsonyi.dev/blog/2025/carapace</id><content type="html" xml:base="https://jsonyi.dev/blog/2025/carapace/"><![CDATA[<p>Containers feel like magic. You run a command, and suddenly your process is isolated in its own little world. But under the hood, there is no magic, just Linux primitives.</p> <p>In this post, I’ll walk through how I built <strong>Carapace</strong>, a lightweight container runtime written in Rust. I’ll explain the core technologies that make containers possible, such as<strong>Namespaces</strong>, <strong>Cgroups</strong>, and <strong>Chroot</strong>, and how Rust’s safety guarantees make it the perfect language for systems programming.</p> <h2 id="the-core-primitives">The Core Primitives</h2> <p>A “container” is effectively a process that is lied to by the kernel. We achieve this deception using three main tools:</p> <ol> <li><strong>Namespaces:</strong> Isolate <em>what</em> a process can see (PIDs, mounts, network).</li> <li><strong>Cgroups (Control Groups):</strong> Limit <em>how much</em> a process can use (CPU, RAM).</li> <li><strong>Chroot:</strong> Change <em>where</em> the process thinks the root of the filesystem is.</li> </ol> <h2 id="phase-1-the-skeleton-namespaces">Phase 1: The Skeleton (Namespaces)</h2> <p>The first step is to create a process that is “disconnected” from the host. We use the <code class="language-plaintext highlighter-rouge">unshare</code> syscall to create new “rooms” for the Hostname (UTS) and Process IDs (PID).</p> <p>I designed Carapace with a “Parent-Child” architecture:</p> <ol> <li><strong>Parent:</strong> Sets up isolation and spawns the child.</li> <li><strong>Child:</strong> Configures the environment (hostname, filesystem) and executes the user’s command.</li> </ol> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">use</span> <span class="nn">nix</span><span class="p">::</span><span class="nn">sched</span><span class="p">::{</span><span class="n">unshare</span><span class="p">,</span> <span class="n">CloneFlags</span><span class="p">};</span>
<span class="k">use</span> <span class="nn">std</span><span class="p">::</span><span class="nn">process</span><span class="p">::{</span><span class="n">Command</span><span class="p">,</span> <span class="n">Stdio</span><span class="p">};</span>

<span class="k">fn</span> <span class="nf">run</span><span class="p">(</span><span class="n">cmd</span><span class="p">:</span> <span class="nb">String</span><span class="p">,</span> <span class="n">args</span><span class="p">:</span> <span class="nb">Vec</span><span class="o">&lt;</span><span class="nb">String</span><span class="o">&gt;</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Result</span><span class="o">&lt;</span><span class="p">()</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="nd">println!</span><span class="p">(</span><span class="s">"Parent: Setting up isolation..."</span><span class="p">);</span>

    <span class="c1">// 1. Create new "rooms" for Hostname (UTS) and PIDs</span>
    <span class="k">let</span> <span class="n">flags</span> <span class="o">=</span> <span class="nn">CloneFlags</span><span class="p">::</span><span class="n">CLONE_NEWUTS</span> <span class="p">|</span> <span class="nn">CloneFlags</span><span class="p">::</span><span class="n">CLONE_NEWPID</span> <span class="p">|</span> <span class="nn">CloneFlags</span><span class="p">::</span><span class="n">CLONE_NEWNS</span><span class="p">;</span>
    <span class="nf">unshare</span><span class="p">(</span><span class="n">flags</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>

    <span class="c1">// 2. Re-Exec: spawn a copy of OURSELVES into those new rooms</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">child</span> <span class="o">=</span> <span class="nn">Command</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="s">"/proc/self/exe"</span><span class="p">)</span>
        <span class="nf">.arg</span><span class="p">(</span><span class="s">"child"</span><span class="p">)</span> <span class="c1">// Call our internal "child" subcommand</span>
        <span class="nf">.arg</span><span class="p">(</span><span class="n">cmd</span><span class="p">)</span>
        <span class="nf">.args</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="nf">.spawn</span><span class="p">()</span><span class="o">?</span><span class="p">;</span>

    <span class="n">child</span><span class="nf">.wait</span><span class="p">()</span><span class="o">?</span><span class="p">;</span>
    <span class="nf">Ok</span><span class="p">(())</span>
<span class="p">}</span>
</code></pre></div></div> <p>By re-executing <code class="language-plaintext highlighter-rouge">/proc/self/exe</code>, we allow the child process to start fresh inside the new namespaces.</p> <h2 id="phase-2-the-jail-filesystem">Phase 2: The Jail (Filesystem)</h2> <p>Isolation isn’t enough if the container can still see the host’s files. We need to trap the process in a separate root filesystem (I used Alpine Linux for this).</p> <p>We use <code class="language-plaintext highlighter-rouge">chroot</code> to change the root directory and <code class="language-plaintext highlighter-rouge">chdir</code> to ensure the process is physically inside the new jail.</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">use</span> <span class="nn">nix</span><span class="p">::</span><span class="nn">unistd</span><span class="p">::{</span><span class="n">chroot</span><span class="p">,</span> <span class="n">chdir</span><span class="p">};</span>

<span class="k">fn</span> <span class="nf">child</span><span class="p">(</span><span class="n">cmd</span><span class="p">:</span> <span class="nb">String</span><span class="p">,</span> <span class="n">args</span><span class="p">:</span> <span class="nb">Vec</span><span class="o">&lt;</span><span class="nb">String</span><span class="o">&gt;</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Result</span><span class="o">&lt;</span><span class="p">()</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="nd">println!</span><span class="p">(</span><span class="s">"Child: Entering chroot jail..."</span><span class="p">);</span>
    
    <span class="c1">// 1. The Lock: Restrict filesystem access to the 'rootfs' folder</span>
    <span class="nf">chroot</span><span class="p">(</span><span class="s">"rootfs"</span><span class="p">)</span><span class="o">?</span><span class="p">;</span> 
    
    <span class="c1">// 2. The Entry: Move current working directory into the new root</span>
    <span class="nf">chdir</span><span class="p">(</span><span class="s">"/"</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>

    <span class="c1">// 3. Mount /proc so tools like 'ps' work</span>
    <span class="nf">mount</span><span class="p">(</span>
        <span class="nf">Some</span><span class="p">(</span><span class="s">"proc"</span><span class="p">),</span>
        <span class="s">"/proc"</span><span class="p">,</span>
        <span class="nf">Some</span><span class="p">(</span><span class="s">"proc"</span><span class="p">),</span>
        <span class="nn">MsFlags</span><span class="p">::</span><span class="nf">empty</span><span class="p">(),</span>
        <span class="nn">None</span><span class="p">::</span><span class="o">&lt;&amp;</span><span class="nb">str</span><span class="o">&gt;</span>
    <span class="p">)</span><span class="o">?</span><span class="p">;</span>

    <span class="c1">// ... execute user command ...</span>
    <span class="nf">Ok</span><span class="p">(())</span>
<span class="p">}</span>
</code></pre></div></div> <p><strong>Crucial Detail:</strong> After <code class="language-plaintext highlighter-rouge">chroot</code>, the <code class="language-plaintext highlighter-rouge">/proc</code> directory is empty. We must manually mount the <code class="language-plaintext highlighter-rouge">proc</code> pseudo-filesystem so that tools like <code class="language-plaintext highlighter-rouge">ps</code> can read process information from the kernel.</p> <h2 id="phase-3-resource-limits-cgroups">Phase 3: Resource Limits (Cgroups)</h2> <p>To prevent a container from hogging the entire machine’s CPU or memory, we use <strong>Control Groups (Cgroups)</strong>.</p> <p>I implemented a “Sandwich Pattern” to manage the lifecycle of these resources:</p> <ol> <li><strong>Setup:</strong> Create the Cgroup and set limits <em>before</em> the child starts.</li> <li><strong>Run:</strong> The child process joins the Cgroup.</li> <li><strong>Cleanup:</strong> Delete the Cgroup <em>after</em> the child exits.</li> </ol> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">run</span><span class="p">(</span><span class="n">cmd</span><span class="p">:</span> <span class="nb">String</span><span class="p">,</span> <span class="n">args</span><span class="p">:</span> <span class="nb">Vec</span><span class="o">&lt;</span><span class="nb">String</span><span class="o">&gt;</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Result</span><span class="o">&lt;</span><span class="p">()</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="c1">// 1. Setup: Build the "cage" first</span>
    <span class="nf">setup_cgroups</span><span class="p">()</span><span class="o">?</span><span class="p">;</span>

    <span class="c1">// ... start child process ...</span>

    <span class="n">child</span><span class="nf">.wait</span><span class="p">()</span><span class="o">?</span><span class="p">;</span>
    
    <span class="c1">// 2. Cleanup: Remove the "cage" to prevent memory leaks</span>
    <span class="nf">clean_cgroups</span><span class="p">()</span><span class="o">?</span><span class="p">;</span>

    <span class="nf">Ok</span><span class="p">(())</span>
<span class="p">}</span>
</code></pre></div></div> <p>If we didn’t clean up, the Cgroup directories would persist in <code class="language-plaintext highlighter-rouge">/sys/fs/cgroup/</code>, eventually causing a memory leak in the kernel.</p> <h2 id="why-rust">Why Rust?</h2> <p>Writing a container runtime involves a lot of raw system calls. In C, handling <code class="language-plaintext highlighter-rouge">unshare</code>, <code class="language-plaintext highlighter-rouge">chroot</code>, and memory management manually is a minefield.</p> <p>Rust gives me:</p> <ul> <li><strong><code class="language-plaintext highlighter-rouge">Result&lt;T, E&gt;</code>:</strong> Forces me to handle every syscall failure (no more silent crashes).</li> <li><strong>Safety:</strong> The borrow checker ensures I’m not leaking memory or accessing invalid pointers.</li> <li><strong>FFI:</strong> I even integrated a C++ inspector using Rust’s FFI capabilities to read kernel versions!</li> </ul> <h2 id="conclusion">Conclusion</h2> <p>Building Carapace taught me that containers are a clever composition of Linux features that have existed for years. By implementing them from scratch, you gain a much deeper appreciation for the engineering behind Docker and Kubernetes.</p> <p>Check out the full source code on <a href="https://github.com/yi-json/carapace">GitHub</a>.</p>]]></content><author><name></name></author><category term="low-level"/><category term="rust"/><category term="systems"/><category term="containers"/><category term="linux"/><summary type="html"><![CDATA[A deep dive into Linux Namespaces, Cgroups, and how I built a secure container runtime using Rust.]]></summary></entry><entry><title type="html">Universal Types</title><link href="https://jsonyi.dev/blog/2024/universal-types/" rel="alternate" type="text/html" title="Universal Types"/><published>2024-08-23T00:00:00+00:00</published><updated>2024-08-23T00:00:00+00:00</updated><id>https://jsonyi.dev/blog/2024/universal-types</id><content type="html" xml:base="https://jsonyi.dev/blog/2024/universal-types/"><![CDATA[<p>Universal types are very useful for performing generic programming, which allows you to use the same code over different types. For instance, the C++ STL (Standard Template Library) allows you to work on things like containers over any arbitrary type. You would surely not want to re-implement the logic for every concrete type that you use. Such a feature is known as parametric polymorphism. It is different from the other kind of polymorphism normally found in object-oriented languages that allows for overloading and run-time dispatch, which is known as ad-hoc polymorphism.</p> <p>To formally introduce and discuss universal types, we work in the context of System F with universal (or polymorphic) types. System F is an extension of the simply-typed lambda calculus with universal quantification over types. The typing rules for System F are given below:</p> <p>\begin{prooftree} \RightLabel{(var)} \AxiomC{$x:T \in \Gamma $} \UnaryInfC{$\Gamma \vdash x : T$} \end{prooftree}</p> <p>\begin{prooftree} \RightLabel{(abs)} \AxiomC{$\Gamma, x : T_1 \vdash t_2: T_2 $} \UnaryInfC{$\Gamma \vdash \lambda x : T_1.t_2 : T_1 \rightarrow T_2$} \end{prooftree}</p> <p>\begin{prooftree} \RightLabel{(app)} \AxiomC{$\Gamma \vdash t_1 : T_{11} \rightarrow T_{12}$} \AxiomC{$\Gamma \vdash t_2 : T_{11} $} \BinaryInfC{$\Gamma \vdash t_1\ t_2 : T_{12} $} \end{prooftree}</p> <p>\begin{prooftree} \RightLabel{(tabs)} \AxiomC{$\Gamma, X \vdash t_2 : T_2$} \UnaryInfC{$\Gamma \vdash \lambda X.t_2 : \forall X.T_2$} \end{prooftree}</p> <p>\begin{prooftree} \RightLabel{(tapp)} \AxiomC{$\Gamma \vdash t_1 : \forall X.T_{12} $} \UnaryInfC{$\Gamma \vdash t_1\ [T_2] : [X \rightarrow T_2] T_{12} $} \end{prooftree}</p> <p>The first three rules are our old friends from the simply-typed lambda calculus, corresponding to variable typing, lambda abstraction, and lambda application. The rules \(\textsf{tabs}\) and \(\textsf{tapp}\) (type abstraction and type application) are new. We use capitalized variable names in order to denote that it is a type variable. So \(\textsf{tabs}\) says that if we add a type \(X\) in our context and we can derive a term \(t_2\) of type \(T_2\) from it, then we can produce an abstraction that takes in any type \(X\) and returns a term of type \(T_2\) when applied. The standard technique of applying alpha conversion applies in the case that there are conflicting variable names in nested closures.</p> <p>As an example, consider the empty context \(\Gamma = \cdot\). If we add a type variable \(X\) to it, we can derive the polymorphic identity function \(\lambda X. \lambda x : X.x\) with type \(\forall X.X \rightarrow X\).</p> <p>\(\textsf{tapp}\) says that given a lambda abstraction \(t_1\) over types, we can apply it on any type \(T_2\) to obtain a result that have instances of \(X\) substituted by \(T_2\). We put square brackets around \(T_2\) on the bottom left to make explicit that this is a type application, while the bracket notation on the right refers to substitution. Continuing off from our previous example, we can perform the application \(\lambda X. \lambda x [\textsf{Nat}]\) to specialize our polymorphic function to be \(\textsf{Nat} \rightarrow \textsf{Nat}\).</p> <p>Since we allow quantification over types, System F is a second-order lambda-calculus. In fact, we can go further and quantify over types of types, which is known as kinds. You can then say why not go further and take the type over kinds, and if repeat this process indefinitely you will actually achieve the language known as System \(\text{F}_\omega\)!</p> <p>Languages from the ML family provides parametric polymorphism. However, it seems like not all is well. Consider the following piece of innocent OCaml code that simply defines the identity function and then tries to call it with two values of different types:</p> <figure class="highlight"><pre><code class="language-ocaml" data-lang="ocaml"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
</pre></td><td class="code"><pre><span class="k">let</span> <span class="n">id</span> <span class="o">:</span> <span class="k">'</span><span class="n">a</span> <span class="o">-&gt;</span> <span class="k">'</span><span class="n">a</span> <span class="o">=</span> <span class="k">fun</span> <span class="n">x</span> <span class="o">-&gt;</span> <span class="n">x</span> <span class="k">in</span>
<span class="p">(</span><span class="n">id</span> <span class="mi">0</span><span class="o">,</span> <span class="n">id</span> <span class="s2">"hello"</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></figure> <p>Despite how we seemingly typed it to use any generic type variable, the compiler complains to us:</p> <figure class="highlight"><pre><code class="language-ocaml" data-lang="ocaml"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="code"><pre><span class="nc">File</span> <span class="s2">"./ident.ml"</span><span class="o">,</span> <span class="n">line</span> <span class="mi">2</span><span class="o">,</span> <span class="n">characters</span> <span class="mi">10</span><span class="o">-</span><span class="mi">17</span><span class="o">:</span>
<span class="mi">2</span> <span class="o">|</span> <span class="p">(</span><span class="n">id</span> <span class="mi">0</span><span class="o">,</span> <span class="n">id</span> <span class="s2">"hello"</span><span class="p">)</span>
<span class="o">^^^^^^^</span>
<span class="nc">Error</span><span class="o">:</span> <span class="nc">This</span> <span class="n">expression</span> <span class="n">has</span> <span class="k">type</span> <span class="kt">string</span> <span class="n">but</span> <span class="n">an</span> <span class="n">expression</span> <span class="n">was</span> <span class="n">expected</span> <span class="k">of</span> <span class="k">type</span>
<span class="kt">int</span>
</pre></td></tr></tbody></table></code></pre></figure> <p>This is because OCaml uses the Hindley-Milner type inference algorithm in order to perform type reconstruction. From a high level point of view, it produces constraints on the types based on how they are used, and then tries to unify these constraints in the most general way possible. As such, it discovers both constraints \('a = \textsf{int}\) and also \('a = \textsf{string}\), which cannot be unified (on the other hand, something like \(X = Y, Y = \textsf{int}\) can be unified). If we want the example to work, we actually need to provide more information to the compiler and tell it that we actually want \('a\) to be universally quantified by using polymorphic type annotations:</p> <figure class="highlight"><pre><code class="language-ocaml" data-lang="ocaml"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
</pre></td><td class="code"><pre><span class="k">let</span> <span class="n">id</span> <span class="o">:</span> <span class="k">'</span><span class="n">a</span><span class="o">.</span> <span class="k">'</span><span class="n">a</span> <span class="o">-&gt;</span> <span class="k">'</span><span class="n">a</span> <span class="o">=</span> <span class="k">fun</span> <span class="n">x</span> <span class="o">-&gt;</span> <span class="n">x</span> <span class="k">in</span>
<span class="p">(</span><span class="n">id</span> <span class="mi">0</span><span class="o">,</span> <span class="n">id</span> <span class="s2">"hello"</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></figure> <p>Notice how the typing rule <code class="language-plaintext highlighter-rouge">'a. 'a -&gt; 'a</code> closely resembles our type \(\forall X.X \rightarrow X\) in System F.</p> <p>Another way to achieve the same thing is by using explicit type parameters, which now really looks like our term in System F, \(\lambda A. \lambda x.x\):</p> <figure class="highlight"><pre><code class="language-ocaml" data-lang="ocaml"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
</pre></td><td class="code"><pre><span class="k">let</span> <span class="n">id</span> <span class="o">=</span> <span class="k">fun</span> <span class="p">(</span><span class="k">type</span> <span class="n">a</span><span class="p">)</span> <span class="p">(</span><span class="n">x</span> <span class="o">:</span> <span class="n">a</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">x</span> <span class="k">in</span>
<span class="p">(</span><span class="n">id</span> <span class="mi">0</span><span class="o">,</span> <span class="n">id</span> <span class="s2">"hello"</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></figure> <p>The first approach (polymorphic type annotations) is more idiomatic as explicit type parameters could cause issues when the function is recursive (<a href="https://blog.janestreet.com/ensuring-that-a-function-is-polymorphic-in-ocaml-3-12/">see the following post if you want more information</a>).</p> <p>However, was this failure just a limitation of our type inference algorithm, and might there be a smarter way such that type inference in a language with first-class parametric polymorphism is possible? Interestingly enough, this was a very difficult question to answer, and was an open problem for around 20 years before Joe Wells proved that it is actually undecidable. Therefore, as a compromise, OCaml uses a weaker form of polymorphism known as let-polymorphism. Let-polymorphism essentially substitutes the binding into the resulting expression itself before typechecking, which allows each instance to be constrained independently of the others.</p>]]></content><author><name>json</name></author><category term="code"/><category term="pl-theory"/><summary type="html"><![CDATA[Universal types are very useful for performing generic programming, which allows you to use the same code over different types. For instance, the C++ STL allows you to work on things like containers over any arbitrary type. In this post, we understand the theoretical foundations underpinning universal types, and conclude with the landmark result that typechecking with universal types is undecidable.]]></summary></entry></feed>